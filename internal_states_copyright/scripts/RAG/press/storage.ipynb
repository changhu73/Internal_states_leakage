{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|██████████| 238/238 [00:08<00:00, 26.66it/s]\n",
      "Encoding texts: 100%|██████████| 238/238 [00:09<00:00, 25.21it/s]\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the quantized FAISS index on input vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n",
      "WARNING clustering 1898 points to 256 centroids: please provide at least 9984 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index training completed.\n",
      "Adding input vectors to the quantized FAISS index...\n",
      "Input vectors added to the FAISS index.\n",
      "Quantized FAISS index has been saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import zlib\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load JSON data and prepare pairs\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for non-infringement\n",
    "    non_infringement_inputs = [entry['input'] for entry in non_infringement_json_data]\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for infringement\n",
    "    infringement_inputs = [entry['input'] for entry in infringement_json_data]\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "\n",
    "    # Create structured matching pairs\n",
    "    non_infringement_pairs = list(zip(non_infringement_inputs, non_infringement_references))\n",
    "    infringement_pairs = list(zip(infringement_inputs, infringement_references))\n",
    "\n",
    "    # Combine all pairs into a single list\n",
    "    all_pairs = non_infringement_pairs + infringement_pairs\n",
    "    return all_pairs\n",
    "\n",
    "# Example usage\n",
    "all_pairs = load_data(\n",
    "    ' test_division/extra_30.non_infringement.json',\n",
    "    ' test_division/extra_30.infringement.json'\n",
    ")\n",
    "\n",
    "# Extract `input` texts and `references` for storage\n",
    "input_texts = [pair[0] for pair in all_pairs]\n",
    "references = [pair[1] for pair in all_pairs]\n",
    "\n",
    "# Encode `input` texts and `reference` texts in batches\n",
    "def batch_encode_texts(model, texts, batch_size=8):\n",
    "    all_vectors = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding texts\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_vectors = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "        all_vectors.append(batch_vectors.cpu().numpy())\n",
    "    return np.vstack(all_vectors)\n",
    "\n",
    "# Encode the `input` texts and `reference` texts\n",
    "input_vectors = batch_encode_texts(model, input_texts)\n",
    "reference_vectors = batch_encode_texts(model, references)\n",
    "\n",
    "# Quantize embeddings to int8 (reduce memory usage)\n",
    "def quantize_embeddings(embeddings, dtype=np.int8):\n",
    "    min_val = embeddings.min()\n",
    "    max_val = embeddings.max()\n",
    "    scale = (max_val - min_val) / (np.iinfo(dtype).max - np.iinfo(dtype).min)\n",
    "    quantized_embeddings = np.round((embeddings - min_val) / scale).astype(dtype)\n",
    "    return quantized_embeddings, scale, min_val\n",
    "\n",
    "# Compress the embeddings using zlib\n",
    "def compress_embedding(embedding):\n",
    "    # Convert to bytes and compress\n",
    "    compressed = zlib.compress(embedding.tobytes())\n",
    "    return compressed\n",
    "\n",
    "# Quantize and compress embeddings\n",
    "input_vectors_quantized, scale_input, min_input = quantize_embeddings(input_vectors, dtype=np.int8)\n",
    "reference_vectors_quantized, scale_reference, min_reference = quantize_embeddings(reference_vectors, dtype=np.int8)\n",
    "\n",
    "# Setting up FAISS Index\n",
    "dimension = input_vectors_quantized.shape[1]\n",
    "nlist = 3  # Number of clusters (for coarse quantization)\n",
    "m = 8  # Number of sub-vector centroids (for PQ)\n",
    "nbits = 8  # Bits per sub-vector\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(dimension)  # Use flat index for quantization\n",
    "gpu_index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
    "\n",
    "# Train the quantized index on input vectors\n",
    "print(\"Training the quantized FAISS index on input vectors...\")\n",
    "gpu_index.train(input_vectors_quantized)\n",
    "print(\"FAISS index training completed.\")\n",
    "\n",
    "# Add input vectors to the quantized FAISS index\n",
    "print(\"Adding input vectors to the quantized FAISS index...\")\n",
    "gpu_index.add(input_vectors_quantized)\n",
    "print(\"Input vectors added to the FAISS index.\")\n",
    "\n",
    "# Save the quantized FAISS index\n",
    "faiss.write_index(gpu_index, 'faiss_index_quantized.index')\n",
    "print(\"Quantized FAISS index has been saved.\")\n",
    "\n",
    "# Setting up SQLite database to store vectors (input and reference embeddings)\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('rag_db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(''' \n",
    "        CREATE TABLE IF NOT EXISTS documents (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            input_embedding BLOB NOT NULL,\n",
    "            reference_embedding BLOB NOT NULL,\n",
    "            input_scale FLOAT NOT NULL,\n",
    "            input_min FLOAT NOT NULL,\n",
    "            reference_scale FLOAT NOT NULL,\n",
    "            reference_min FLOAT NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Store embeddings in the database\n",
    "def store_embeddings(conn, input_embeddings, reference_embeddings, scale_input, min_input, scale_reference, min_reference):\n",
    "    cursor = conn.cursor()\n",
    "    for input_emb, ref_emb in zip(input_embeddings, reference_embeddings):\n",
    "        # Compress the embeddings\n",
    "        compressed_input = compress_embedding(input_emb)\n",
    "        compressed_ref = compress_embedding(ref_emb)\n",
    "\n",
    "        # Insert compressed embeddings and quantization metadata\n",
    "        cursor.execute('INSERT INTO documents (input_embedding, reference_embedding, input_scale, input_min, reference_scale, reference_min) VALUES (?, ?, ?, ?, ?, ?)', \n",
    "                       (compressed_input, compressed_ref, scale_input, min_input, scale_reference, min_reference))  # Store compressed embeddings and metadata\n",
    "    conn.commit()\n",
    "\n",
    "# Store embeddings in the database\n",
    "conn = setup_database()\n",
    "store_embeddings(conn, input_vectors_quantized, reference_vectors_quantized, scale_input, min_input, scale_reference, min_reference)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
