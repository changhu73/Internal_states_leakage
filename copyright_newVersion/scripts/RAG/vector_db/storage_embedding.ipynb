{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|██████████| 238/238 [00:08<00:00, 26.76it/s]\n",
      "Encoding texts: 100%|██████████| 238/238 [00:09<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the index on input vectors...\n",
      "Index training completed.\n",
      "Adding input vectors to the index...\n",
      "Input vectors added to the index.\n",
      "FAISS index has been saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Set device for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load JSON data and prepare pairs\n",
    "def load_data(non_infringement_file, infringement_file):\n",
    "    with open(non_infringement_file, 'r', encoding='utf-8') as file:\n",
    "        non_infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for non-infringement\n",
    "    non_infringement_inputs = [entry['input'] for entry in non_infringement_json_data]\n",
    "    non_infringement_references = [entry['reference'] for entry in non_infringement_json_data]\n",
    "\n",
    "    with open(infringement_file, 'r', encoding='utf-8') as file:\n",
    "        infringement_json_data = json.load(file)\n",
    "\n",
    "    # Extract input and reference text for infringement\n",
    "    infringement_inputs = [entry['input'] for entry in infringement_json_data]\n",
    "    infringement_references = [entry['reference'] for entry in infringement_json_data]\n",
    "\n",
    "    # Create structured matching pairs\n",
    "    non_infringement_pairs = list(zip(non_infringement_inputs, non_infringement_references))\n",
    "    infringement_pairs = list(zip(infringement_inputs, infringement_references))\n",
    "\n",
    "    # Combine all pairs into a single list\n",
    "    all_pairs = non_infringement_pairs + infringement_pairs\n",
    "    return all_pairs\n",
    "\n",
    "# Example usage\n",
    "all_pairs = load_data(\n",
    "    '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.non_infringement.json',\n",
    "    '/home/guangwei/LLM-COPYRIGHT/copyright_newVersion/test_division/extra_30.infringement.json'\n",
    ")\n",
    "\n",
    "# Extract `input` texts and `references` for storage\n",
    "input_texts = [pair[0] for pair in all_pairs]\n",
    "references = [pair[1] for pair in all_pairs]\n",
    "\n",
    "# Encode `input` texts and `reference` texts in batches\n",
    "def batch_encode_texts(model, texts, batch_size=8):\n",
    "    all_vectors = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding texts\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_vectors = model.encode(batch, convert_to_tensor=True, device=device)\n",
    "        all_vectors.append(batch_vectors.cpu().numpy())\n",
    "    return np.vstack(all_vectors)\n",
    "\n",
    "# Encode the `input` texts and `reference` texts\n",
    "input_vectors = batch_encode_texts(model, input_texts)\n",
    "reference_vectors = batch_encode_texts(model, references)\n",
    "\n",
    "# Initialize FAISS index for `input` vectors\n",
    "dimension = input_vectors.shape[1]\n",
    "nlist = 3  # Example number of clusters\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "gpu_index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train and add vectors to the FAISS index\n",
    "print(\"Training the index on input vectors...\")\n",
    "gpu_index.train(input_vectors)\n",
    "print(\"Index training completed.\")\n",
    "print(\"Adding input vectors to the index...\")\n",
    "gpu_index.add(input_vectors)\n",
    "print(\"Input vectors added to the index.\")\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(gpu_index, 'faiss_index.index')\n",
    "print(\"FAISS index has been saved.\")\n",
    "\n",
    "# Setting up SQLite database to store vectors (input and reference embeddings)\n",
    "def setup_database():\n",
    "    conn = sqlite3.connect('rag_db.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(''' \n",
    "        CREATE TABLE IF NOT EXISTS documents (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            input_embedding BLOB NOT NULL,\n",
    "            reference_embedding BLOB NOT NULL\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Store embeddings in the database\n",
    "def store_embeddings(conn, input_embeddings, reference_embeddings):\n",
    "    cursor = conn.cursor()\n",
    "    for input_emb, ref_emb in zip(input_embeddings, reference_embeddings):\n",
    "        # Convert embeddings to binary data (BLOB format)\n",
    "        input_blob = input_emb.tobytes()\n",
    "        ref_blob = ref_emb.tobytes()\n",
    "        cursor.execute('INSERT INTO documents (input_embedding, reference_embedding) VALUES (?, ?)', \n",
    "                       (input_blob, ref_blob))  # Store embeddings\n",
    "    conn.commit()\n",
    "\n",
    "# Store embeddings in the database\n",
    "conn = setup_database()\n",
    "store_embeddings(conn, input_vectors, reference_vectors)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zdh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
